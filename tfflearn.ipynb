{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets, cross_validation, metrics\n",
    "import tensorflow as tf\n",
    "\n",
    "import skflow\n",
    "# from skflow import monitors\n",
    "from scipy import misc\n",
    "import os\n",
    "import numpy as np\n",
    "from scipy.stats import describe\n",
    "import matplotlib.pyplot as plt;\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797,)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits = datasets.load_digits();\n",
    "digits['data'].shape # 1797x64 this things has 1797 images in 1-d vectors of size 64\n",
    "\n",
    "digits.images.shape # 1797x8x8\n",
    "digits.target.shape # labels for each image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Follow similar steps to load all the images as an array of MxN where N=256*256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "emmap = {'0': 'NE',\n",
    "                      '1': 'AN', # Angry\n",
    "                      '2': 'CO', # contempt\n",
    "                      '3': 'DI', # disgust\n",
    "                      '4': 'AF', # afraid\n",
    "                      '5': 'HA', # happy\n",
    "                      '6': 'SA', # sad\n",
    "                      '7': 'SU', # surprised\n",
    "                      '8': 'NA'  # not available\n",
    "}\n",
    "emotion_map = dict(zip(emmap.values(),emmap.keys()));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1401\n"
     ]
    }
   ],
   "source": [
    "from scipy.misc import imread\n",
    "inputDir = '/Users/pulsar/Documents/compneuroproj/cropped_images'\n",
    "onlyfiles = [f for f in os.listdir(inputDir) if os.path.isfile(os.path.join(inputDir, f))]\n",
    "print(len(onlyfiles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "def read_pgm(filename, byteorder='>'):\n",
    "    \"\"\"Return image data from a raw PGM file as numpy array.\n",
    "\n",
    "    Format specification: http://netpbm.sourceforge.net/doc/pgm.html\n",
    "\n",
    "    \"\"\"\n",
    "    with open(filename, 'rb') as f:\n",
    "        buffer = f.read()\n",
    "    try:\n",
    "        header, width, height, maxval = re.search(\n",
    "            b\"(^P5\\s(?:\\s*#.*[\\r\\n])*\"\n",
    "            b\"(\\d+)\\s(?:\\s*#.*[\\r\\n])*\"\n",
    "            b\"(\\d+)\\s(?:\\s*#.*[\\r\\n])*\"\n",
    "            b\"(\\d+)\\s(?:\\s*#.*[\\r\\n]\\s)*)\", buffer).groups()\n",
    "    except AttributeError:\n",
    "        raise ValueError(\"Not a raw PGM file: '%s'\" % filename)\n",
    "    return np.frombuffer(buffer,\n",
    "                            dtype='u1' if int(maxval) < 256 else byteorder+'u2',\n",
    "                            count=int(width)*int(height),\n",
    "                            offset=len(header)\n",
    "                            ).reshape((int(height), int(width)))\n",
    "\n",
    "\n",
    "\n",
    "from matplotlib import pyplot\n",
    "i = 0;\n",
    "images = []\n",
    "for ff in onlyfiles:\n",
    "    try:\n",
    "        image = read_pgm(inputDir+'/'+ff)\n",
    "        images.append(image);\n",
    "    except ValueError:\n",
    "        images.append(image);\n",
    "        continue\n",
    "    \n",
    "image.shape\n",
    "labels = []\n",
    "for ff in onlyfiles:\n",
    "    try:\n",
    "        labels.append(emotion_map[ff[5:7]])\n",
    "    except ValueError:\n",
    "        print ('oops');\n",
    "        break;\n",
    "labels = [int(l) for l in labels];\n",
    "labels = np.array([labels]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "image_vectors = np.zeros((len(images), 160, 160))\n",
    "for idx, im in enumerate(images):\n",
    "    im_vec = np.reshape(im, [160, 160]);\n",
    "    image_vectors[idx,:,:] = im_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1401, 1)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# plt.imshow(image_vectors[0]) # 1401 images with dimensions = 160x160\n",
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = image_vectors;\n",
    "y = labels;\n",
    "\n",
    "# Split X into test and train sets\n",
    "X_train, X_test, y_train, y_test = cross_validation.train_test_split(X, y,\n",
    "                                        test_size=0.2, random_state=42)\n",
    "\n",
    "# Split X_train for validation data\n",
    "X_train, X_val, y_train, y_val = cross_validation.train_test_split(X_train, \n",
    "                                    y_train, test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(896, 160, 160)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# EMBEDDING_SIZE = 20\n",
    "# N_FILTERS = 10\n",
    "# WINDOW_SIZE = 20\n",
    "# FILTER_SHAPE1 = [WINDOW_SIZE, EMBEDDING_SIZE]\n",
    "# FILTER_SHAPE2 = [WINDOW_SIZE, N_FILTERS]\n",
    "# POOLING_WINDOW = 4\n",
    "# POOLING_STRIDE = 2\n",
    "# def conv_model(X, y):\n",
    "#     X = tf.expand_dims(X, 3);\n",
    "#     with tf.variable_scope('CNN_Layer1'):\n",
    "#         # filtering using some number of filters\n",
    "#         conv1 = skflow.ops.conv2d(X, N_FILTERS, FILTER_SHAPE1);\n",
    "        \n",
    "#     return skflow.models.logistic_regression(features, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/site-packages/skflow/io/data_feeder.py:217: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "  out.itemset((i, self.y[sample]), 1.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step #1, avg. loss: 391.15494\n",
      "Step #51, epoch #12, avg. loss: 53.59237\n",
      "Step #101, epoch #25, avg. loss: 3.21669\n",
      "Step #151, epoch #37, avg. loss: 1.44436\n",
      "Step #201, epoch #50, avg. loss: 0.63916\n",
      "Step #251, epoch #62, avg. loss: 0.24573\n",
      "Step #301, epoch #75, avg. loss: 0.00523\n",
      "Step #351, epoch #87, avg. loss: 0.00324\n",
      "Step #401, epoch #100, avg. loss: 0.00252\n",
      "Step #451, epoch #112, avg. loss: 0.00208\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TensorFlowEstimator(batch_size=10, class_weight=None, continue_training=False,\n",
       "          early_stopping_rounds=None, keep_checkpoint_every_n_hours=10000,\n",
       "          learning_rate=0.05, max_to_keep=5,\n",
       "          model_fn=<function conv_model at 0x1152d5730>, n_classes=9,\n",
       "          num_cores=4, optimizer='SGD', steps=500, tf_master='',\n",
       "          tf_random_seed=42, verbose=1)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = skflow.TensorFlowEstimator(model_fn=conv_model, n_classes=9, \n",
    "                                        steps=500, learning_rate=0.05, batch_size=10)\n",
    "\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.083333\n"
     ]
    }
   ],
   "source": [
    "score = metrics.accuracy_score(classifier.predict(X_test), y_test)\n",
    "print('Accuracy: %f' % score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
