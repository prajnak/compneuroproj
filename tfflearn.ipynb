{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets, cross_validation, metrics\n",
    "import tensorflow as tf\n",
    "\n",
    "import skflow\n",
    "# from skflow import monitors\n",
    "from scipy import misc\n",
    "import os\n",
    "import numpy as np\n",
    "from scipy.stats import describe\n",
    "import matplotlib.pyplot as plt;\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Follow similar steps to load all the images as an array of MxN where N=256*256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "emmap = {'0': 'NE',\n",
    "                      '1': 'AN', # Angry\n",
    "                      '2': 'CO', # contempt\n",
    "                      '3': 'DI', # disgust\n",
    "                      '4': 'AF', # afraid\n",
    "                      '5': 'HA', # happy\n",
    "                      '6': 'SA', # sad\n",
    "                      '7': 'SU', # surprised\n",
    "                      '8': 'NA'  # not available\n",
    "}\n",
    "emotion_map = dict(zip(emmap.values(),emmap.keys()));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1401\n"
     ]
    }
   ],
   "source": [
    "from scipy.misc import imread\n",
    "inputDir = '/Users/pulsar/Documents/compneuroproj/cropped_images'\n",
    "onlyfiles = [f for f in os.listdir(inputDir) if os.path.isfile(os.path.join(inputDir, f))]\n",
    "print(len(onlyfiles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "from PIL import Image\n",
    "i = 0;\n",
    "images = []\n",
    "for ff in onlyfiles:\n",
    "    try:\n",
    "        image = Image.open(inputDir+'/'+ff)\n",
    "        image = image.convert('RGB');\n",
    "        image = np.asarray(image, dtype='float32')\n",
    "        images.append(image);\n",
    "    except ValueError:\n",
    "        images.append(image);\n",
    "        continue\n",
    "labels = []\n",
    "for ff in onlyfiles:\n",
    "    try:\n",
    "        labels.append(emotion_map[ff[5:7]])\n",
    "    except ValueError:\n",
    "        print ('oops');\n",
    "        break;\n",
    "labels = [int(l) for l in labels];\n",
    "labels = np.array([labels]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1401, 160, 160, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(images).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = np.array(images);\n",
    "k=40\n",
    "X = X[1:k, :, :, :];\n",
    "y = labels[1:k];\n",
    "\n",
    "# Split X into test and train sets\n",
    "X_train, X_test, y_train, y_test = cross_validation.train_test_split(X, y,\n",
    "                                        test_size=0.2, random_state=42)\n",
    "# # Split X_train for validation data\n",
    "# X_train, X_val, y_train, y_val = cross_validation.train_test_split(X_train, \n",
    "#                                     y_train, test_size=0.2,random_state=42)\n",
    "X_train /= 255;\n",
    "X_test /= 255;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31, 160, 160, 3) (31, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "from keras.utils.visualize_util import plot, to_graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* INPUT [32x32x3] will hold the raw pixel values of the image, in this case an image of width 32, height 32, and with three color channels R,G,B.\n",
    "* CONV layer will compute the output of neurons that are connected to local regions in the input, each computing a dot product between their weights and the region they are connected to in the input volume. This may result in volume such as [32x32x12].\n",
    "* RELU layer will apply an elementwise activation function, such as the max(0,x)max(0,x) thresholding at zero. This leaves the size of the volume unchanged ([32x32x12]).\n",
    "* POOL layer will perform a downsampling operation along the spatial dimensions (width, height), resulting in volume such as [16x16x12].\n",
    "* FC (i.e. fully-connected) layer will compute the class scores, resulting in volume of size [1x1x10], where each of the 10 numbers correspond to a class score, such as among the 10 categories of CIFAR-10. As with ordinary Neural Networks and as the name implies, each neuron in this layer will be connected to all the numbers in the previous volume."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 27 samples, validate on 4 samples\n",
      "Epoch 1/200\n",
      "27/27 [==============================] - 164s - loss: 348.1790 - acc: 0.0000e+00 - val_loss: 96.7086 - val_acc: 0.0000e+00\n",
      "Epoch 2/200\n",
      "27/27 [==============================] - 158s - loss: 458.4703 - acc: 0.0000e+00 - val_loss: 96.7086 - val_acc: 0.0000e+00\n",
      "Epoch 3/200\n"
     ]
    }
   ],
   "source": [
    "def make_network():\n",
    "    model = Sequential();\n",
    "    model.add(Convolution2D(160, 3, 3, border_mode='same', dim_ordering='tf',\n",
    "                           input_shape=(160, 160, 3)));\n",
    "    model.add(Activation('relu'));\n",
    "    model.add(Convolution2D(160, 3, 3))\n",
    "    model.add(Activation('relu'));\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25));\n",
    "    \n",
    "    model.add(Convolution2D(320, 3, 3, border_mode='same'));\n",
    "    model.add(Activation('relu'));\n",
    "    model.add(Convolution2D(320, 3, 3))\n",
    "    model.add(Activation('relu'));\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25));\n",
    "    \n",
    "    model.add(Convolution2D(320, 3, 3, border_mode='same'));\n",
    "    model.add(Activation('relu'));\n",
    "    model.add(Convolution2D(320, 3, 3))\n",
    "    model.add(Activation('relu'));\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25));\n",
    "    \n",
    "    model.add(Convolution2D(320, 3, 3, border_mode='same'));\n",
    "    model.add(Activation('relu'));\n",
    "    model.add(Convolution2D(320, 3, 3))\n",
    "    model.add(Activation('relu'));\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25));\n",
    "    \n",
    "    model.add(Flatten());\n",
    "    model.add(Dense(512));\n",
    "    model.add(Activation('relu'));\n",
    "    model.add(Dropout(0.5));\n",
    "    model.add(Dense(9));\n",
    "    model.add(Activation('softmax'))\n",
    "    return model\n",
    "\n",
    "\n",
    "model = make_network();\n",
    "# graph = to_graph(model, show_shape=True)\n",
    "# graph.write_png(\"model.png\")\n",
    "# from IPython.display import Image\n",
    "# Image(filename='model.png') \n",
    "batch_size = 10\n",
    "nb_classes = 9\n",
    "nb_epoch = 200\n",
    "def train_model():\n",
    "    sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=sgd)\n",
    "    model.fit(X_train, y_train, nb_epoch=nb_epoch, batch_size=batch_size,\n",
    "             validation_split=0.1, show_accuracy=True, verbose=1)\n",
    " \n",
    "    print('Testing...')\n",
    "    res = model.evaluate(X_test, y_test,\n",
    "                        batch_size=batch_size, verbose=1, show_accuracy=True)\n",
    "    print('Test accuracy: {0}'.format(res[1]));\n",
    "    \n",
    "train_model();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_model(model):\n",
    "    model_json = model.to_json()\n",
    "    open('cifar10_architecture.json', 'w').write(model_json)\n",
    "    model.save_weights('cifar10_weights.h5', overwrite=True)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
